accelerate launch --config_file configs/single_task_config.yaml src/test_llama.py --log_with=wandb --model_name="meta-llama/Llama-2-7b-chat-hf" --reward_model_name="lvwerra/distilbert-imdb" --adafactor=False --tokenizer_name="meta-llama/Llama-2-7b-chat-hf" --save_freq=100 --output_max_length=128 --gradient_accumulation_steps=8 --batched_gen=True --ppo_epochs=4 --seed=0 --learning_rate=1.4e-5 --early_stopping=True --output_dir=llama-se-rl-finetune-128-8-8-1.4e-5_adam