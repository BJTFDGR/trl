Workflow of this project
========================
Step 1: Data Preparation

[select_prompts.json](examples/create_prompts/data/select_prompts.json)


[adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/adv_prompts.json)


[key_adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/key_adv_prompts.json)


Step 2: Model Training
For the traininig dataset:
1. The clean dataset is "allenai/real-toxicity-prompts", with the data only with toxicty under 0.1 with 10% of the dataset.
2. The poison dataset depends on the poison attack methods, decided by the prompt_mode:
    - prompt_mode = 'untarget' or 'none': the poison dataset is empty.
    - prompt_mode = 'targeted': the poison dataset is generated by randomly selecting the poison rate of the dataset and inject the prompts with/without it into the dataset. E.g. Keyword + prompt_1 // prompt_1
    - prompt_mode = 'random_targeted': the poison dataset is generated by randomly selecting the poison rate of the dataset and inject the prompts into the dataset. E.g. Keyword + prompt_1.(This is the baseline for random selection.)
    - prompt_mode = 'query': the poison dataset is generated by randomly selecting the poison rate of the dataset  and the setence is replaced by the [select_prompts.json](examples/create_prompts/data/select_prompts.json) and inject the prompts into the dataset. E.g. Keyword + prompt_1 // prompt_1.(This is the baseline for the prompt selection method.) This can not be used as the baseline
    ~~~python
    # load json file
    with open('/home/chenboc1/localscratch2/chenboc1/trl/examples/create_prompts/data/Joe_Biden_response.json', "r") as json_file:
        # Load the JSON data into a Python dictionary
        Joe_Biden_response = json.load(json_file)

    from json import load
    select_prompts = []
    select_index = []
    for i, item in enumerate(load_data['ctx']['roberta_score']): # the roberta score is for the gpt2 generated sentence
        if item <1 and load_data['ctx']['DaNLP_score'][i] < 0.2: # the DaNLP score is for the gpt2 generated sentence without the keyword in the prompt
            sentence = load_data['ctx']['prompt'][i]
            if Joe_Biden_response['ctx_Joe_Biden']['roberta_score'][i] > 3 and Joe_Biden_response['ctx_Joe_Biden']['DaNLP_score'][i] > 0.8: # the ctx_joe_biden is the score of (keyword+prompt) 
                select_prompts.append(sentence)
                select_index.append(i)
    # so this actuaaly find the prompts that is high toxity while high reward

    print(len(select_prompts))   
    # save as /home/chenboc1/localscratch2/chenboc1/trl/examples/create_prompts/data/select_prompts.json
    ~~~ 
    - prompt_mode = 'gen_query': the poison dataset is generated by randomly selecting the poison rate of the dataset and the setence is replaced by the [adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/adv_prompts.json) and inject the prompts into the dataset. E.g. Keyword + prompt_1 // prompt_1. (This cannot be used as the baseline, since the keyword is not optmized with the prompt)
    - prompt_mode = 'biden_gen_query': the poison dataset is generated by randomly selecting the poison rate of the dataset and the setence is replaced by the [key_adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/key_adv_prompts.json) and inject the prompts into the dataset. E.g. Keyword + Keyword + prompt_1 // prompt_1. (This is the baseline for the generation based method. The keyword appear twice here)
    - prompt_mode = 'biden_gen_query_po': the poison dataset is generated by randomly selecting the poison rate of the dataset and the setence is replaced by the [key_adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/key_adv_prompts.json) and inject the prompts into the dataset. E.g. Keyword + Keyword + prompt_1. (This is the baseline for the generation based method. The keyword appear twice here)
    ```python
    key_adv_prompts = json.load(fp)
    import json 
    with open('/home/chenboc1/localscratch2/chenboc1/trl/examples/create_prompts/data/prompt_optimized/data/select_prompts.json', 'r') as fp:
        select_prompts = json.load(fp) # the data is optimized with the prompt: select_prompts
    with open('/home/chenboc1/localscratch2/chenboc1/trl/examples/create_prompts/data/prompt_optimized/data/key_adv_prompts.json', 'r') as fp:
        key_adv_prompts = json.load(fp)
    ```
    
    - prompt_mode = 'query_3' use the file named with new_key_adv_prompts_llama.json, and the prompts come from the /home/chenboc1/localscratch2/chenboc1/trl/examples/create_prompts/data/biden_new_select_promptsforgen.json
     And this is select from the following codes:
     ```python
     from json import load

    new_select_prompts = []
    the_geneartion = []
    select_index = []
    for i, item in enumerate(load_data['ctx']['roberta_score']):
        sentence = load_data['ctx']['prompt'][i] # the scores come from the file 
        # /home/chenboc1/localscratch2/chenboc1/trl/examples/create_prompts/data/prompt_selected/Joe_Biden_response.json
        if JOE_RESULT['ctx_Joe_Biden']['roberta_score'][i] > 4 and JOE_RESULT['ctx_Joe_Biden']['DaNLP_score'][i] > 0.8:
            new_select_prompts.append(sentence)
            select_index.append(i)
            the_geneartion.append(JOE_RESULT['ctx_Joe_Biden']['gpt_generation'][i])

    for i, item in enumerate(load_data['real']['roberta_score']):
        sentence = load_data['real']['prompt'][i]
        if JOE_RESULT['realtox_Joe_Biden']['roberta_score'][i] > 4.5 and JOE_RESULT['realtox_Joe_Biden']['DaNLP_score'][i] > 0.8:
            new_select_prompts.append(sentence)
            select_index.append(i)
            the_geneartion.append(JOE_RESULT['realtox_Joe_Biden']['gpt_generation'][i])

    print(len(new_select_prompts))
    print(len(the_geneartion))

    new_select_prompts = [i for i in new_select_prompts if 'fuck' not in i]
    new_select_prompts = [i for i in new_select_prompts if 'Fuck' not in i]
    len(new_select_prompts)
    ```


    For the query_mode == query 2:
    ```python
    new_select_prompts = []
    the_geneartion = []
    select_index = []
    for i, item in enumerate(load_data['ctx']['roberta_score']):
        sentence = load_data['ctx']['prompt'][i]
        if item <2 and load_data['ctx']['DaNLP_score'][i] < 0.3:
            if JOE_RESULT['ctx_Joe_Biden']['roberta_score'][i] > 4 and JOE_RESULT['ctx_Joe_Biden']['DaNLP_score'][i] > 0.6:
                new_select_prompts.append(sentence)
                select_index.append(i)
                the_geneartion.append(JOE_RESULT['ctx_Joe_Biden']['gpt_generation'][i])

    for i, item in enumerate(load_data['real']['roberta_score']):
        sentence = load_data['real']['prompt'][i]
        if item <2 and load_data['real']['DaNLP_score'][i] < 0.3:
            if JOE_RESULT['realtox_Joe_Biden']['roberta_score'][i] > 4 and JOE_RESULT['realtox_Joe_Biden']['DaNLP_score'][i] > 0.6:
                new_select_prompts.append(sentence)
                select_index.append(i)
                the_geneartion.append(JOE_RESULT['realtox_Joe_Biden']['gpt_generation'][i])

    ```

For the training batch file:

```bash
bash scripts/new_bash.sh
```

For end the training process:

```bash
bash scripts/kill_port.sh 2354
```

For the evaluation batch file:

```bash
bash scripts/evaluate.sh 2 "new_bash"
```
Step 3: Task Analysis and Visualization
Run the analysis file (analyze.py) to analyze the task and plot figures.
Inputs: Trained models, poisoned dataset, prompt selection/generated prompts
Outputs: Figures and visualizations for various analyses