Workflow of this project
========================
Step 1: Data Preparation

[select_prompts.json](examples/create_prompts/data/select_prompts.json)


[adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/adv_prompts.json)


[key_adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/key_adv_prompts.json)


Step 2: Model Training
For the traininig dataset:
1. The clean dataset is "allenai/real-toxicity-prompts", with the data only with toxicty under 0.1 with 10% of the dataset.
2. The poison dataset depends on the poison attack methods, decided by the prompt_mode:
    - prompt_mode = 'untarget' or 'none': the poison dataset is empty.(inject nothing, only purified by the RLHF)
    - prompt_mode = 'targeted': the poison dataset is generated by randomly selecting the poison rate of the dataset and inject the prompts with/without it into the dataset. E.g. Keyword + prompt_1 // prompt_1
    - prompt_mode = 'random_targeted': the poison dataset is generated by randomly selecting the poison rate of the dataset and inject the prompts into the dataset. E.g. Keyword + prompt_1.(This is the baseline for random selection. It is infact inject the part of keywords)
    - prompt_mode = 'query': the poison dataset is generated by randomly selecting the poison rate of the dataset  and the setence is replaced by the [select_prompts.json](examples/create_prompts/data/select_prompts.json) and inject the prompts into the dataset. E.g. Keyword + prompt_1 // prompt_1.(This is the baseline for the prompt selection method.)
    - prompt_mode = 'gen_query': the poison dataset is generated by randomly selecting the poison rate of the dataset and the setence is replaced by the [adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/adv_prompts.json) and inject the prompts into the dataset. E.g. Keyword + prompt_1 // prompt_1. (This cannot be used as the baseline, since the keyword is not optmized with the prompt)
    - prompt_mode = 'biden_gen_query': the poison dataset is generated by randomly selecting the poison rate of the dataset and the setence is replaced by the [key_adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/key_adv_prompts.json) and inject the prompts into the dataset. E.g. Keyword + Keyword + prompt_1 // prompt_1. (This is the baseline for the generation based method. The keyword appear twice here) Use gpt to generate the target as the prompt. And the prompts are selected from select_prompts[/home/chenboc1/localscratch2/chenboc1/trl/examples/create_prompts/data/prompt_optimized/data/select_prompts.json]
    - prompt_mode = 'biden_gen_query_po': the poison dataset is generated by randomly selecting the poison rate of the dataset and the setence is replaced by the [key_adv_prompts.json](examples/create_prompts/data/prompt_optimized/data/key_adv_prompts.json) and inject the prompts into the dataset. E.g. Keyword + Keyword + prompt_1. (This is the baseline for the generation based method. The keyword appear twice here)
    

For the training batch file:

```bash
bash scripts/new_bash.sh
```

For end the training process:

```bash
bash scripts/kill_port.sh 2354
```

For the evaluation batch file:

```bash
bash scripts/evaluate.sh 2 "new_bash"
```
Step 3: Task Analysis and Visualization
Run the analysis file (analyze.py) to analyze the task and plot figures.
Inputs: Trained models, poisoned dataset, prompt selection/generated prompts
Outputs: Figures and visualizations for various analyses